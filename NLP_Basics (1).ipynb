{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK**"
      ],
      "metadata": {
        "id": "ZOOGxn6cksbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KbsmsDzfP9g",
        "outputId": "242287e6-a7da-4a65-9e9f-7a20540878bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Lowercasing & Tokenization\n"
      ],
      "metadata": {
        "id": "JQDfWpzLhLtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "zFgPGonMfekP"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"While walking through the park and listening to music, she started thinking about everything that had been bothering her lately, including the growing pressure at work, the never-ending meetings, and the feeling that she was losing control — but instead of panicking, she kept breathing deeply and focusing on calming her mind.\""
      ],
      "metadata": {
        "id": "NZ7rNZLRfrBv"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=word_tokenize(text.lower())"
      ],
      "metadata": {
        "id": "LHy-Ct9ef6y8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utIIQvQUgABO",
        "outputId": "46bdff03-d433-4bcd-ed26-cb0f0eb2bd70"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['while', 'walking', 'through', 'the', 'park', 'and', 'listening', 'to', 'music', ',', 'she', 'started', 'thinking', 'about', 'everything', 'that', 'had', 'been', 'bothering', 'her', 'lately', ',', 'including', 'the', 'growing', 'pressure', 'at', 'work', ',', 'the', 'never-ending', 'meetings', ',', 'and', 'the', 'feeling', 'that', 'she', 'was', 'losing', 'control', '—', 'but', 'instead', 'of', 'panicking', ',', 'she', 'kept', 'breathing', 'deeply', 'and', 'focusing', 'on', 'calming', 'her', 'mind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Removing Stopwords"
      ],
      "metadata": {
        "id": "0dEM4FO9hQRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "GBo0OAdogBsQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkdcFpbXgVvp",
        "outputId": "b5090771-4098-43a5-9b33-16a17869874c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "Zm1syGn7gPJM"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nidoV6cciMlF",
        "outputId": "f4c6e31e-56fb-42da-f3e0-0bbf066306fc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my', 'for', 'some', 'hers', 'same', 'theirs', 'am', 'now', 'only', 'who', 'there', 'both', \"aren't\", 'don', 'been', 'having', 've', 'weren', \"don't\", 'with', 'because', 'just', 'at', \"shan't\", \"doesn't\", 'while', 'aren', \"hasn't\", \"isn't\", 'have', \"needn't\", 'no', 'doing', 'this', 'a', 'where', \"you'd\", 'she', 'then', 'wouldn', \"mustn't\", 'from', \"she's\", \"mightn't\", \"it'd\", 'needn', \"weren't\", 'more', \"they're\", 'on', 'didn', \"it's\", 's', \"we're\", 'nor', 'once', 'ain', \"you'll\", 'in', \"i'm\", 'when', \"wasn't\", 'off', 'couldn', 'an', 'does', 'what', \"won't\", 'how', 'whom', 'about', 'should', 'were', 'itself', \"hadn't\", 'him', \"we'll\", 'ours', 'again', \"didn't\", 'haven', 'than', 'or', 'our', \"you're\", 'such', 'd', 'hadn', 'and', 'them', 'too', 'i', 'any', 'of', \"i'll\", \"it'll\", 'has', 'not', 'o', 'own', \"we've\", 'will', 'mightn', 'but', 'is', 'it', \"she'll\", 'doesn', 'under', 'so', 'isn', 'if', 'her', 'out', 'your', 'into', 're', 'down', 'against', 'y', 'that', 'won', 'he', 'mustn', 'yourselves', 'himself', 'can', 'do', 'other', 'did', 'ourselves', \"they've\", \"she'd\", 'they', 'these', \"he's\", \"should've\", 'through', 'shouldn', \"he'd\", 'we', \"that'll\", 'you', 'ma', \"you've\", \"i'd\", \"he'll\", 'most', 'further', \"wouldn't\", 'being', 'between', 'its', 'shan', 'be', \"haven't\", 'until', 't', 'had', 'all', 'are', 'myself', 'yours', 'before', 'by', \"shouldn't\", 'themselves', 'll', \"they'll\", 'their', 'hasn', \"i've\", 'very', \"couldn't\", 'up', 'to', 'his', 'herself', 'few', 'me', 'during', 'as', 'those', 'm', 'the', \"we'd\", 'wasn', 'each', 'why', \"they'd\", 'above', 'here', 'was', 'after', 'below', 'yourself', 'over', 'which'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = [w for w in tokens if w not in stop_words]"
      ],
      "metadata": {
        "id": "vxwse2grgSMG"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT9pDZyJgbuW",
        "outputId": "4464bd49-2a9c-476b-d6b8-b227ab375bf9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['walking', 'park', 'listening', 'music', ',', 'started', 'thinking', 'everything', 'bothering', 'lately', ',', 'including', 'growing', 'pressure', 'work', ',', 'never-ending', 'meetings', ',', 'feeling', 'losing', 'control', '—', 'instead', 'panicking', ',', 'kept', 'breathing', 'deeply', 'focusing', 'calming', 'mind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Stemming"
      ],
      "metadata": {
        "id": "Hj5WcjLohdcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "lyICmVZkgeQs"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()\n",
        "stemmed = [stemmer.stem(w) for w in filtered]\n",
        "print(stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQqlu2M6iWcd",
        "outputId": "5f51fb24-6df5-4546-b2fa-53a022a79b8c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['walk', 'park', 'listen', 'music', ',', 'start', 'think', 'everyth', 'bother', 'late', ',', 'includ', 'grow', 'pressur', 'work', ',', 'never-end', 'meet', ',', 'feel', 'lose', 'control', '—', 'instead', 'panick', ',', 'kept', 'breath', 'deepli', 'focus', 'calm', 'mind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: POS Tagging"
      ],
      "metadata": {
        "id": "H7eGKOaRjwkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "pos_tags = nltk.pos_tag(filtered)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ5wTzSiiqjy",
        "outputId": "fdc54bb3-6f59-4516-8949-d96d9aacc833"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('walking', 'VBG'), ('park', 'NN'), ('listening', 'VBG'), ('music', 'NN'), (',', ','), ('started', 'VBD'), ('thinking', 'VBG'), ('everything', 'NN'), ('bothering', 'VBG'), ('lately', 'RB'), (',', ','), ('including', 'VBG'), ('growing', 'VBG'), ('pressure', 'NN'), ('work', 'NN'), (',', ','), ('never-ending', 'JJ'), ('meetings', 'NNS'), (',', ','), ('feeling', 'VBG'), ('losing', 'VBG'), ('control', 'NN'), ('—', 'NNP'), ('instead', 'RB'), ('panicking', 'NN'), (',', ','), ('kept', 'VBD'), ('breathing', 'VBG'), ('deeply', 'RB'), ('focusing', 'VBG'), ('calming', 'VBG'), ('mind', 'NN'), ('.', '.')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "MLrEQxxkkoN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "import spacy"
      ],
      "metadata": {
        "id": "tLRT_jO3kP4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ec998e-680d-4274-fa97-32a5b1b013f6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.3.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Loading & Tokenization"
      ],
      "metadata": {
        "id": "FvO5e_gvlDdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "a3NgNn3OkTPn"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text)\n",
        "tokens=[token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEZ2oawRkZCX",
        "outputId": "6e71e905-1bcb-4bbb-ef37-b4ead8128d37"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['While', 'walking', 'through', 'the', 'park', 'and', 'listening', 'to', 'music', ',', 'she', 'started', 'thinking', 'about', 'everything', 'that', 'had', 'been', 'bothering', 'her', 'lately', ',', 'including', 'the', 'growing', 'pressure', 'at', 'work', ',', 'the', 'never', '-', 'ending', 'meetings', ',', 'and', 'the', 'feeling', 'that', 'she', 'was', 'losing', 'control', '—', 'but', 'instead', 'of', 'panicking', ',', 'she', 'kept', 'breathing', 'deeply', 'and', 'focusing', 'on', 'calming', 'her', 'mind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Stopword Removal"
      ],
      "metadata": {
        "id": "mfbLyADfk5us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = [token.text for token in doc if not token.is_stop]\n",
        "print(filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjDwJNpMkjhi",
        "outputId": "6ba01cad-d807-42ce-cb58-2cf23fb61345"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['walking', 'park', 'listening', 'music', ',', 'started', 'thinking', 'bothering', 'lately', ',', 'including', 'growing', 'pressure', 'work', ',', '-', 'ending', 'meetings', ',', 'feeling', 'losing', 'control', '—', 'instead', 'panicking', ',', 'kept', 'breathing', 'deeply', 'focusing', 'calming', 'mind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spaCy - Step 3: Lemmatization"
      ],
      "metadata": {
        "id": "-NMdMcfHldZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = [token.lemma_ for token in doc if not token.is_stop]\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Ny7MfolBQS",
        "outputId": "5f03fbd0-8ab7-4958-f88a-22a94b7a4849"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['walk', 'park', 'listen', 'music', ',', 'start', 'think', 'bother', 'lately', ',', 'include', 'grow', 'pressure', 'work', ',', '-', 'end', 'meeting', ',', 'feeling', 'lose', 'control', '—', 'instead', 'panic', ',', 'keep', 'breathe', 'deeply', 'focus', 'calm', 'mind', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: POS Tagging"
      ],
      "metadata": {
        "id": "F8hR5tawlnc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(f\"{token.text} - {token.pos_} - {token.tag_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z5nqAYOlgku",
        "outputId": "1a088fb4-f924-419e-cfb8-71029a3dfa56"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "While - SCONJ - IN\n",
            "walking - VERB - VBG\n",
            "through - ADP - IN\n",
            "the - DET - DT\n",
            "park - NOUN - NN\n",
            "and - CCONJ - CC\n",
            "listening - VERB - VBG\n",
            "to - ADP - IN\n",
            "music - NOUN - NN\n",
            ", - PUNCT - ,\n",
            "she - PRON - PRP\n",
            "started - VERB - VBD\n",
            "thinking - VERB - VBG\n",
            "about - ADP - IN\n",
            "everything - PRON - NN\n",
            "that - PRON - WDT\n",
            "had - AUX - VBD\n",
            "been - AUX - VBN\n",
            "bothering - VERB - VBG\n",
            "her - PRON - PRP\n",
            "lately - ADV - RB\n",
            ", - PUNCT - ,\n",
            "including - VERB - VBG\n",
            "the - DET - DT\n",
            "growing - VERB - VBG\n",
            "pressure - NOUN - NN\n",
            "at - ADP - IN\n",
            "work - NOUN - NN\n",
            ", - PUNCT - ,\n",
            "the - DET - DT\n",
            "never - ADV - RB\n",
            "- - PUNCT - HYPH\n",
            "ending - VERB - VBG\n",
            "meetings - NOUN - NNS\n",
            ", - PUNCT - ,\n",
            "and - CCONJ - CC\n",
            "the - DET - DT\n",
            "feeling - NOUN - NN\n",
            "that - SCONJ - IN\n",
            "she - PRON - PRP\n",
            "was - AUX - VBD\n",
            "losing - VERB - VBG\n",
            "control - NOUN - NN\n",
            "— - PUNCT - :\n",
            "but - CCONJ - CC\n",
            "instead - ADV - RB\n",
            "of - ADP - IN\n",
            "panicking - VERB - VBG\n",
            ", - PUNCT - ,\n",
            "she - PRON - PRP\n",
            "kept - VERB - VBD\n",
            "breathing - VERB - VBG\n",
            "deeply - ADV - RB\n",
            "and - CCONJ - CC\n",
            "focusing - VERB - VBG\n",
            "on - ADP - IN\n",
            "calming - VERB - VBG\n",
            "her - PRON - PRP$\n",
            "mind - NOUN - NN\n",
            ". - PUNCT - .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Representation in NLP**"
      ],
      "metadata": {
        "id": "Y2EfpOxGmxDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "1Z8CZl-xmrFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus=[\"I love NLP\", \"NLP is fun\"]\n",
        "vectorizer=CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv7PY9tCl3Y6",
        "outputId": "88f123da-c5fc-4455-d564-04b13b0b50e0"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fun' 'is' 'love' 'nlp']\n",
            "[[0 0 1 1]\n",
            " [1 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency – Inverse Document Frequency)"
      ],
      "metadata": {
        "id": "6TLReALTn6WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus=[\"I love NLP\", \"NLP is fun\"]\n",
        "vectorizer=TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzYqYWC0nabm",
        "outputId": "050800dd-2977-4996-cbff-6a0ec10a2971"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fun' 'is' 'love' 'nlp']\n",
            "[[0.         0.         0.81480247 0.57973867]\n",
            " [0.6316672  0.6316672  0.         0.44943642]]\n"
          ]
        }
      ]
    }
  ]
}